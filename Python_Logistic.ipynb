{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Python-Logistic.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/shuwang127/Python-Logistic/blob/master/Python_Logistic.ipynb",
      "authorship_tag": "ABX9TyO5Vb4V4iwM0iy0K4APCoe6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shuwang127/Python-Logistic/blob/master/Python_Logistic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zyc8y4TELzBL",
        "colab_type": "text"
      },
      "source": [
        "Read data from .txt file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbbEKG_lsKrl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "f = open('./drive/My Drive/Colab Notebooks/Student-Pass-Fail-Data.txt', 'r')\n",
        "next(f) # skip the first row.\n",
        "data = np.array([[int(num) for num in line.split(',')] for line in f])\n",
        "print('data:\\n', data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTMTEuduNDDR",
        "colab_type": "text"
      },
      "source": [
        "Divide data into features (Self_Study_Daily, Tuition_Monthly) and labels (Pass_Or_Fail)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKredOxTNGb7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = data[:,:-1]\n",
        "y = data[:,-1]\n",
        "print('x:\\n', x, '\\ny:\\n', y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdApLeQlOkPU",
        "colab_type": "text"
      },
      "source": [
        "Split the data into train and test sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ncDF11sOnfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rY-WXcp8PmDn",
        "colab_type": "text"
      },
      "source": [
        "Define the Logistic Regression model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wg1BNtmLPov0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "logistic_regression = LogisticRegression()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxdN1Q0HP41j",
        "colab_type": "text"
      },
      "source": [
        "Fit the training data with Logistic Regression model. (take two parameters: x_train and y_train)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2ATkxUEPzU0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logistic_regression.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHd1XOIxQEZ7",
        "colab_type": "text"
      },
      "source": [
        "Get predictions for testing data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-ce_0xxQHkj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = logistic_regression.predict(x_test)\n",
        "print('y_pred:\\n', y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8a695yMQPKb",
        "colab_type": "text"
      },
      "source": [
        "Calculate the testing accuracy with actual labels and predicted labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qBGVQjNQTzB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "print('Testing accuracy = %.2f%%.' % (accuracy * 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZD9OAYJjQwz1",
        "colab_type": "text"
      },
      "source": [
        "Plot the decision boundary visually."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMm2pj8iQyqs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "for cls in range(2):\n",
        "    plt.scatter(x=x_train[y_train==cls, 0], y=x_train[y_train==cls, 1], alpha=0.5, c=('red', 'green')[cls], marker=('x', '^')[cls], label=cls) # plot training set.\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIRgMQH6KhcJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x1, x2 = np.meshgrid(np.arange(min(x[:,0])-1, max(x[:,0])+1, 0.02), np.arange(min(x[:,1])-1, max(x[:,1])+1, 0.02)) # mesh.\n",
        "Z = logistic_regression.predict(np.array([x1.ravel(), x2.ravel()]).T).reshape(x1.shape) # get predictions for mesh.\n",
        "plt.contourf(x1, x2, Z, alpha=0.3, cmap=ListedColormap(('red', 'green'))) # plot decision boundary.\n",
        "for cls in range(2):\n",
        "    plt.scatter(x=x_train[y_train==cls, 0], y=x_train[y_train==cls, 1], alpha=0.5, c=('red', 'green')[cls], marker=('x', '^')[cls], label=cls) # plot training set.\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4t9LjFGKma2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x1, x2 = np.meshgrid(np.arange(min(x[:,0])-1, max(x[:,0])+1, 0.02), np.arange(min(x[:,1])-1, max(x[:,1])+1, 0.02)) # mesh.\n",
        "Z = logistic_regression.predict(np.array([x1.ravel(), x2.ravel()]).T).reshape(x1.shape) # get predictions for mesh.\n",
        "plt.contourf(x1, x2, Z, alpha=0.3, cmap=ListedColormap(('red', 'green'))) # plot decision boundary.\n",
        "for cls in range(2):\n",
        "    plt.scatter(x=x_train[y_train==cls, 0], y=x_train[y_train==cls, 1], alpha=0.5, c=('red', 'green')[cls], marker=('x', '^')[cls], label=cls) # plot training set.\n",
        "    plt.scatter(x=x_test[y_test == cls, 0], y=x_test[y_test == cls, 1], alpha=0.8, c=('red', 'green')[cls], marker=('o', 's')[cls], label=cls) # plot testing set.\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}